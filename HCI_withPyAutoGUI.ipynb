{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qmint001/cv2/blob/main/HCI_withPyAutoGUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QLHssWnAglS",
        "outputId": "68ca763c-9733-4159-ce91-f1f006016340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cv'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (211/211), done.\u001b[K\n",
            "remote: Compressing objects: 100% (204/204), done.\u001b[K\n",
            "remote: Total 211 (delta 33), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (211/211), 197.60 MiB | 21.49 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n",
            "Updating files: 100% (156/156), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/fenago/cv/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human-computer interaction (HCI)\n",
        "\n",
        "**Human-computer interaction (HCI)** focuses on the interfaces between people and computers. Initially concerned with personal computers, HCI now has evolved into a multidisciplinary field, combining practices from a number of fields including:\n",
        "* Computer Science\n",
        "* Psychology\n",
        "* Design\n",
        "* Sociology\n",
        "* Ergonomics\n",
        "\n",
        "and many more.\n",
        "\n",
        "![HCI-features](https://opencv.org/wp-content/uploads/2021/08/c0-m6-hci-features.png)\n",
        "## Examples of HCI\n",
        "\n",
        "From the QWERTY keyboard to VR and AR, everything falls under the umbrella of HCI. Even the voice based assistants such as Siri, Alexa and Google assistant are part of HCI.\n",
        "\n",
        "Google [Project Soli](https://atap.google.com/soli/) is one of many examples where HCI is being taken to new levels and getting immense attention from various industrious including Automation, UX Design, Automobiles, Gaming and even Healthcare.\n",
        "\n",
        "![Soli](https://opencv.org/wp-content/uploads/2021/08/c0-m6-soli-gif.gif)\n",
        "\n",
        "The above is a demonstration of how Google plans to incorporate miniature radar to understand human motions and create gesture based inputs on computing devices like smartphones and smart-watches in the Project Soli.\n",
        "\n",
        "In this notebook, we will learn about **PyAutoGUI** and see how we can use it for creating our own applications of HCI.\n"
      ],
      "metadata": {
        "id": "iySNvdIqCgps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyAutoGUI\n",
        "\n",
        "*PyAutoGUI* lets our Python scripts control the mouse and keyboard to automate interactions with other applications. It provides a easy way to make fun HCI applications from scratch. It works on Windows, macOS and Linux.\n",
        "\n",
        "**Note:** Most operating systems will require you to grant specific permissions to let your script drive inputs as if coming from your mouse and keyboard.\n",
        "\n",
        "PyAutoGUI has several features:\n",
        "\n",
        "* Moving the mouse and clicking or typing in the windows of other applications.\n",
        "* Sending keystrokes to applications (for example, to fill out forms).\n",
        "* Take screenshots, and given an image (for example, of a button or checkbox), find it on the screen.\n",
        "* Locate an application’s window, and move, resize, maximize, minimize, or close it (Windows-only, currently)\n",
        "* Display message boxes for user interaction while your GUI automation script runs.\n"
      ],
      "metadata": {
        "id": "FCkPfOG8DMos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyAutoGUI -qqq\n",
        "\n",
        "import pyautogui"
      ],
      "metadata": {
        "id": "0bYAg62wAvnX",
        "outputId": "d1621256-228c-4705-b701-ac17e51d26b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.2/171.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mouse Control Functions\n",
        "\n",
        "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n",
        "\n",
        "## Screen Size and Mouse Position:\n",
        "\n",
        "Locations on your screen are referred to by X and Y Cartesian coordinates as demonstrated below:\n",
        "```\n",
        "0,0       X increases -->\n",
        "+---------------------------+\n",
        "|                           | Y increases\n",
        "|                           |     |\n",
        "|   1920 x 1080 screen      |     |\n",
        "|                           |     V\n",
        "|                           |\n",
        "|                           |\n",
        "+---------------------------+ 1919, 1079\n",
        "\n",
        "```\n",
        "\n",
        "The screen resolution size is returned by the `size()` function as a tuple of two integers. The current X and Y coordinates of the mouse cursor are returned by the `position()` function.\n",
        "\n",
        "### <font color=\"green\">Function Syntax </font>\n",
        "``` python\n",
        "    size = pyautogui.size()\n",
        "    location = pyautogui.position()\n",
        "```\n",
        "\n",
        "## Mouse Movement\n",
        "\n",
        "The `moveTo()` function will move the mouse cursor to the X and Y integer coordinates you pass it.\n",
        "\n",
        "### <font color=\"green\">Function Syntax </font>\n",
        "``` python\n",
        "    pyautogui.moveTo(X, Y, duration)\n",
        "```\n",
        "\n",
        "1. `X` X coordinate of destination point.\n",
        "2. `Y` Y coordinate of destination point.\n",
        "3. `duration` optional flag  of time (in seconds) the movement should take.\n",
        "\n",
        "If you want to move the mouse cursor over a few pixels relative to its current position, use the `move()` function. This function has similar parameters as `moveTo()`.\n",
        "\n",
        "## Mouse Drag\n",
        "\n",
        "PyAutoGUI’s `dragTo()` and `drag()` functions have similar parameters as the `moveTo()` and `move()` functions. In addition, they have a button keyword which can be set to 'left', 'middle', and 'right' for which mouse button to hold down while dragging.\n",
        "\n",
        "### <font color=\"green\">Function Syntax </font>\n",
        "``` python\n",
        "    pyautogui.dragTo( X, Y, duration, button )\n",
        "```\n",
        "\n",
        "1. `X` X coordinate of destination point.\n",
        "2. `Y` Y coordinate of destination point.\n",
        "3. `duration` optional flag  of time (in seconds) the movement should take.\n",
        "4. `button` button to press while dragging the mouse cursor.\n",
        "\n",
        "## Mouse Clicks\n",
        "\n",
        "The `click()` function simulates a single, left-button mouse click at the mouse’s current position. A “click” is defined as pushing the button down and then releasing it up.\n",
        "### <font color=\"green\">Function Syntax </font>\n",
        "``` python\n",
        "    pyautogui.click(X, Y, button, clicks, interval)\n",
        "```\n",
        "\n",
        "1. `X` optional X coordinate of destination point.\n",
        "2. `Y` optional Y coordinate of destination point.\n",
        "3. `button` button to press while dragging the mouse cursor.\n",
        "4. `clicks` number of clicks to perform\n",
        "5. `interval` specify the amount of pause between the clicks in seconds.\n",
        "\n",
        "### <font color=\"green\">PyAutoGUI Documentation</font>\n",
        "\n",
        "[**Mouse control functions**](https://pyautogui.readthedocs.io/en/latest/mouse.html)\n",
        "\n",
        "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n"
      ],
      "metadata": {
        "id": "8z7v3-XiEQeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of mouse control using PyAutoGUI:\n",
        "\n",
        "Consider a use case where you want to automate the drawing of a specific pattern in a drawing or painting software. While a typical user would click and hold the mouse button to draw a stroke in such an application, it is possible to automate such inputs using the `drag` function. Take a look at the following pattern:\n",
        "\n",
        "![HCI-example](https://opencv.org/wp-content/uploads/2021/08/c0-m6-hci-example.png)\n",
        "\n",
        "The code below can be used to draw this pattern on any graphics drawing program. **Note!** This code does nothing more, and nothing less, than send mouse events to the operating system. It does not need to actually communicate directly with the drawing application. In order for this example to work, the drawing app must already be open and in an appropriate mode (e.g. brush or pencil tool activated)."
      ],
      "metadata": {
        "id": "rRE_oUKbE9eL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wait 2 seconds, to give you time to switch to the drawing application.\n",
        "import time\n",
        "import pyautogui\n",
        "time.sleep(2.0)\n",
        "\n",
        "distance = 200\n",
        "while distance > 0:\n",
        "        pyautogui.drag(distance, 0, button='left', duration=0.5)   # move right\n",
        "        distance -= 50\n",
        "        pyautogui.drag(0, distance, button='left', duration=0.5)   # move down\n",
        "        pyautogui.drag(-distance, 0, button='left', duration=0.5)  # move left\n",
        "        distance -= 50\n",
        "        pyautogui.drag(0, -distance, button='left', duration=0.5)  # move up"
      ],
      "metadata": {
        "id": "2nA4TqT_EPA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keyboard Control Functions\n",
        "\n",
        "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n",
        "\n",
        "## The write() Function\n",
        "\n",
        "The primary keyboard function is `write()`. This function will type the characters in the string that is passed.\n",
        "\n",
        "### <font color=\"green\">Function Syntax </font>\n",
        "``` python\n",
        "    pyautogui.write(string, interval)\n",
        "```\n",
        "1. `string` string to type.\n",
        "2. `interval` to add a delay interval in between pressing each character key.\n",
        "\n",
        "## The press(), keyDown(), and keyUp() Functions\n",
        "\n",
        "To press these keys, call the `press()` function and pass it a string from the `pyautogui.KEYBOARD_KEYS` such as **enter**, **esc**, **f1**. See [KEYBOARD_KEYS](https://pyautogui.readthedocs.io/en/latest/keyboard.html#keyboard-keys).\n",
        "\n",
        "### <font color=\"green\">Function Syntax </font>\n",
        "``` python\n",
        "    pyautogui.press(key, presses, interval)\n",
        "```\n",
        "1. `key` string to denote which button to press.\n",
        "2. `presses` number of key presses.\n",
        "3. `interval` to add a delay interval in between pressing the key\n",
        "\n",
        "The `press()` function is really just a wrapper for the `keyDown()` and `keyUp()` functions.\n",
        "\n",
        "## Hotkeys\n",
        "\n",
        "To make pressing hotkeys or keyboard shortcuts convenient, the `hotkey()` can be passed several key strings which will be pressed down in order, and then released in reverse order.\n",
        "\n",
        "### Example:\n",
        "``` python\n",
        "    pyautogui.hotkey('ctrl', 'shift', 'esc')\n",
        "```\n",
        "To add a delay interval in between each press, pass an int or float for the `interval` keyword argument.\n",
        "Above example is same as:\n",
        "\n",
        "``` python\n",
        "    pyautogui.keyDown('ctrl')\n",
        "    pyautogui.keyDown('shift')\n",
        "    pyautogui.keyDown('esc')\n",
        "    pyautogui.keyUp('esc')\n",
        "    pyautogui.keyUp('shift')\n",
        "    pyautogui.keyUp('ctrl')\n",
        "```\n",
        "\n",
        "### <font color=\"green\">PyAutoGUI Documentation</font>\n",
        "\n",
        "[**Keyboard control functions**](https://pyautogui.readthedocs.io/en/latest/keyboard.html)\n",
        "\n",
        "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n"
      ],
      "metadata": {
        "id": "s6M8eyc4Fi-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pyautogui\n",
        "\n",
        "# Give a moment (half a second) to bring up the application window if needed.\n",
        "time.sleep(0.5)\n",
        "\n",
        "# If on a mac OSX machine, use command key instead of ctrl.\n",
        "hotkey = 'command' if 'mac' in pyautogui.platform.platform() else 'ctrl'\n",
        "\n",
        "# Open a new tab using a shortcut key.\n",
        "pyautogui.hotkey(hotkey, 't')\n",
        "\n",
        "# Give time for the browser to open the tab and be ready for user (typing) input.\n",
        "time.sleep(1.0)\n",
        "\n",
        "# Now type a url at a speedy 100 words per minute!\n",
        "pyautogui.write('https://pyautogui.readthedocs.io', 0.01)\n",
        "\n",
        "# Bring 'focus' to the URL bar (shortcut key may vary depending on your browser).\n",
        "time.sleep(0.1)\n",
        "pyautogui.hotkey(hotkey, 'l')\n",
        "\n",
        "# Press enter to load the page.\n",
        "pyautogui.press('enter')"
      ],
      "metadata": {
        "id": "qBbiF4hQFidk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}